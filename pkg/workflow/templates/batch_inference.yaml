name: batch_inference
description: 批量推理 - Batch processing for multiple inference requests

config:
  model: "llama3.2"
  batch_size: 10

steps:
  - id: load_data
    type: resource.load
    input:
      path: "${input.data_path}"
  
  - id: batch_process
    type: inference.batch
    input:
      model: "${config.model}"
      items: "${steps.load_data.items}"
      batch_size: "${config.batch_size}"
    depends_on:
      - load_data

output:
  results: "${steps.batch_process.results}"
